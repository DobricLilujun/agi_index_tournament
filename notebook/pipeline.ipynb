{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149c7016",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'agi_toolkit.hybritePipe' has no attribute 'HybritePipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(hybritePipe)\n\u001b[1;32m      7\u001b[0m samples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe quick brown fox jumps over the lazy dog.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMachine learning models require large datasets for training.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData science involves extracting insights from big data.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 14\u001b[0m hy \u001b[38;5;241m=\u001b[39m \u001b[43mhybritePipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHybritePipeline\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'agi_toolkit.hybritePipe' has no attribute 'HybritePipeline'"
     ]
    }
   ],
   "source": [
    "from agi_toolkit import hybritePipe\n",
    "import importlib\n",
    "\n",
    "importlib.reload(hybritePipe)\n",
    "\n",
    "\n",
    "samples = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Machine learning models require large datasets for training.\",\n",
    "    \"Natural language processing is a challenging field in computer science.\",\n",
    "    \"The weather today is very good and sunny.\",\n",
    "    \"Data science involves extracting insights from big data.\",\n",
    "]\n",
    "hy = hybritePipe.HybritePipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee9de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260972a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hy.reconstruct_dataset(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23647220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Reconstruction Summary ===\n",
      "Original: 5\n",
      "Dictionary-based: 6\n",
      "Back-translation: 13\n",
      "Masked LM: 8\n",
      "Stylistic: 15\n",
      "All variants: 42\n",
      "\n",
      "=== Generalizability Proxies ===\n",
      "vocabulary_diversity: 2.049\n",
      "sentence_length_variance: 13.613\n",
      "syntactic_complexity: 0.990\n",
      "\n",
      "Original 1: The quick brown fox jumps over the lazy dog.\n",
      "dictionary_based:\n",
      "  - The weather today is very excellent and sunny.\n",
      "  - The weather today is highly good and sunny.\n",
      "back_translated:\n",
      "  - The fast brown fox jumps over the lazy dog.\n",
      "  - The fast brown fox jumps on the lazy dog.\n",
      "masked_lm:\n",
      "  - The little brown fox jumps over the lazy dog.\n",
      "  - a quick brown fox jumps over the lazy dog.\n",
      "\n",
      "Original 2: Machine learning models require large datasets for training.\n",
      "dictionary_based:\n",
      "  - The weather today is very excellent and sunny.\n",
      "  - The weather today is highly good and sunny.\n",
      "back_translated:\n",
      "  - The fast brown fox jumps over the lazy dog.\n",
      "  - The fast brown fox jumps on the lazy dog.\n",
      "masked_lm:\n",
      "  - The little brown fox jumps over the lazy dog.\n",
      "  - a quick brown fox jumps over the lazy dog.\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\n=== Reconstruction Summary ===\")\n",
    "# print(f\"Original: {len(results['original'])}\")\n",
    "# print(f\"Dictionary-based: {len(results['dictionary_based'])}\")\n",
    "# print(f\"Back-translation: {len(results['back_translated'])}\")\n",
    "# print(f\"Masked LM: {len(results['masked_lm'])}\")\n",
    "# print(f\"Stylistic: {len(results['stylistic'])}\")\n",
    "# print(f\"All variants: {len(results['all_variants'])}\")\n",
    "\n",
    "# metrics = hy.evaluate_generalizability(results[\"original\"], results[\"all_variants\"])\n",
    "# print(\"\\n=== Generalizability Proxies ===\")\n",
    "# for k, v in metrics.items():\n",
    "#     print(f\"{k}: {v:.3f}\")\n",
    "\n",
    "# # Show a few examples\n",
    "# for i, s in enumerate(results[\"original\"][:2], 1):\n",
    "#     print(f\"\\nOriginal {i}: {s}\")\n",
    "#     ex = 0\n",
    "#     for cat in [\"dictionary_based\", \"back_translated\", \"masked_lm\", \"stylistic\"]:\n",
    "#         picked = []\n",
    "#         for v in results[cat]:\n",
    "#             if ex >= 6:\n",
    "#                 break\n",
    "#             # show first occurrences related in spirit (no strict mapping)\n",
    "#             picked.append(v)\n",
    "#             if len(picked) == 2:\n",
    "#                 break\n",
    "#         if picked:\n",
    "#             print(f\"{cat}:\")\n",
    "#             for p in picked:\n",
    "#                 print(\"  -\", p)\n",
    "#         ex += len(picked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286150ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e05d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agi_index_tournament",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
